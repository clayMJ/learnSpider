Requests
自动爬去html页面自动网络请求提交
robot.txt
网络爬虫排除标准
Beautiful Soup
解析html页面
Projects
实战项目A/B
Re
正则表达式库
Scrapy*
中规模速度更快的网络爬虫

Python IDE
1.交互式
IDLE(入门，代码不超过300行)
Sublime Text(专业编程工具)
2.集成
通用类
Wing(收费，调试功能丰富,适合多人开发)
Eclipse+PyDev(开源)
PyCharm(简单，集成度高，适合复杂编程)
科学计算，数据分析
Canopy(贵,500个库)
Anaconda(开源，800多个库)

定向网络数据爬取和网络解析
Requests:
简单简洁 
官方文档:python-requests.org
r=requests.get(url,params=None,**kwargs)
params:url格外参数
kwargs：12个可访问参数

Response对象属性
r.status_code 
200连接成功 404失败
r.text
url对应页面内容
r.encoding 
HTTP header中猜测的响应内容编码方式,如果header中不存在charset,认为编码为ISO-8859-1
r.apparent_encoding 
从内容中分析出的响应内容编码方式(备用编码方式)
r.content 
HTTP内容响应的二进制方式

Requests库异常
request.ConnectionError
request.HTTPError
request.URLRequired
request.TooManyRedirects 连接远程服务超时异常
request.Timeout 请求URL异常产生超时异常

r.raise_for_status() 判断response异常类型

